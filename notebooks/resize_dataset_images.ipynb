{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ace1e8a45e4fb19f069d6b25bd9bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9043990e881c4bc49d45c6bc9e799aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9b3548191247b3a7a4fe8b2b788cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from datasets import load_dataset\n",
    "import os \n",
    "from utils import resize_preserve_aspect_ratio, pad_to_fixed_size\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "workers = os.cpu_count()\n",
    "\n",
    "dataset_id = \"jordandavis/fashion_people_detections\"\n",
    "ds = load_dataset(dataset_id, split='train', num_proc=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_pil(image_pil, max_size=1024):\n",
    "    # Ensure image is in RGB\n",
    "    if image_pil.mode != \"RGB\":\n",
    "        image_pil = image_pil.convert(\"RGB\")\n",
    "\n",
    "    # Calculate new dimensions preserving aspect ratio\n",
    "    width, height = image_pil.size\n",
    "    scale = min(max_size / width, max_size / height)\n",
    "    new_width = int(width * scale)\n",
    "    new_height = int(height * scale)\n",
    "    image_pil = image_pil.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    # Calculate padding needed to reach 1024x1024\n",
    "    pad_width = (max_size - new_width) // 2\n",
    "    pad_height = (max_size - new_height) // 2\n",
    "\n",
    "    # Apply padding symmetrically\n",
    "    image_pil = ImageOps.expand(\n",
    "        image_pil,\n",
    "        border=(\n",
    "            pad_width,\n",
    "            pad_height,\n",
    "            max_size - new_width - pad_width,\n",
    "            max_size - new_height - pad_height,\n",
    "        ),\n",
    "        fill=(0, 0, 0),\n",
    "    )\n",
    "\n",
    "    return image_pil\n",
    "\n",
    "\n",
    "def resize_images(batch):\n",
    "    batch[\"image\"] = resize_image_pil(batch[\"image\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = os.cpu_count()\n",
    "ds = ds.map(resize_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_coco_polygons_to_mask, overlay_mask\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def sanity_check(ds, row=102, mask_row=2):\n",
    "    image = ds[row][\"image\"]\n",
    "    width, height = image.size\n",
    "    polygons = ds[row][\"mask_metadata\"][mask_row][\"polygons\"]\n",
    "    label = ds[row][\"mask_metadata\"][mask_row][\"label\"]\n",
    "    mask = convert_coco_polygons_to_mask(polygons, width, height)\n",
    "    mask_image = Image.fromarray(mask)\n",
    "    overlay = overlay_mask(image, mask_image, opacity=0.8)\n",
    "\n",
    "    print(label)\n",
    "    display(overlay)\n",
    "\n",
    "\n",
    "row = 3\n",
    "mask_row = 0\n",
    "sanity_check(ds, row, mask_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF THE MASKS ARE ACCURATE THEN PUSH IT TO THE HUB ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_ds.push_to_hub(new_repo_id, commit_message=\"resized images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT python yolo_dataset.py in the CLI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THEN TRAIN THE YOLO MODEL in yolo_train.ipynb notebook ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds[0]['imaage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_image_pil(ds[0][\"image\"]).size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

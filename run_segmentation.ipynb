{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "from scripts.sam_results import SAMResults\n",
    "from utils import (get_coco_style_polygons, pad_to_fixed_size,\n",
    "                   resize_preserve_aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grounded_sam import (\n",
    "    run_grounded_sam_batch,\n",
    "    transform_image_dino,\n",
    "    transform_image_sam,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def load_yaml(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data\n",
    "\n",
    "\n",
    "config_path = \"configs/fashion_people.yml\"\n",
    "data = load_yaml(config_path)\n",
    "\n",
    "\n",
    "def get_labels_dict(config_path):\n",
    "    data = load_yaml(config_path)\n",
    "    labels_dict = data.get(\"names\")\n",
    "    labels_dict = {v: k for k, v in labels_dict.items()}\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "config_path = \"configs/fashion_people.yml\"\n",
    "data = load_yaml(config_path)\n",
    "labels_dict = get_labels_dict(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks_md(results):\n",
    "    results_list = []\n",
    "\n",
    "    for result in results.formatted_results:\n",
    "        mask = result.get(\"mask\")\n",
    "        coco_polygons = get_coco_style_polygons(mask)\n",
    "\n",
    "        # format the polygons\n",
    "        result.update({\"polygons\": coco_polygons})\n",
    "        result.pop(\"mask\")\n",
    "        results_list.append(result)\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [k for k, v in labels_dict.items()]\n",
    "text_prompt = \" . \".join(labels)\n",
    "text_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image(image_pil):\n",
    "    if image_pil.mode != \"RGB\":\n",
    "        image_pil = image_pil.convert(\"RGB\")\n",
    "    image_pil = resize_preserve_aspect_ratio(image_pil, 1024)\n",
    "    image_pil = pad_to_fixed_size(image_pil, (1024, 1024))\n",
    "    return image_pil\n",
    "\n",
    "\n",
    "class Segmentation(Dataset):\n",
    "    def __init__(self, dataset_id=None, image_col=\"image\", image_id_col=None):\n",
    "        self.ds = load_dataset(\n",
    "            dataset_id, split=\"train\", trust_remote_code=True, num_proc=os.cpu_count()\n",
    "        )\n",
    "        self.image_col = image_col\n",
    "        self.image_id_col = image_id_col\n",
    "        self.imgsz = 1024\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        # Get Image ID defaults to index\n",
    "        image_id = item.get(self.image_id_col, idx)\n",
    "\n",
    "        # Get PIL Image\n",
    "        image_pil = item[self.image_col]\n",
    "\n",
    "        image_size = image_pil.size\n",
    "        if image_size[0] != self.imgsz or image_size[1] != self.imgsz:\n",
    "            image_pil = pil_image(image_pil)\n",
    "\n",
    "        # Process dino image\n",
    "        dino_image = transform_image_dino(image_pil)\n",
    "\n",
    "        # Process sam image\n",
    "        sam_image = transform_image_sam(image_pil)\n",
    "\n",
    "        return {\"image_id\": image_id, \"dino_image\": dino_image, \"sam_image\": sam_image, \"image_pil\": image_pil}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the dataset ID and load it as a torch dataset\n",
    "dataset_id = \"jordandavis/fashion_test\"\n",
    "ds = Segmentation(dataset_id=dataset_id, image_col=\"image\", image_id_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all images in dataset using the pil_image function\n",
    "def resize_images(dataset, size=(1024, 1024)):\n",
    "    for i in range(len(dataset)):\n",
    "        image = dataset[i][\"image\"]\n",
    "        image = pil_image(image)\n",
    "        dataset[i][\"image\"] = image\n",
    "        dataset[i][\"width\"] = size[0]\n",
    "        dataset[i][\"height\"] = size[1]\n",
    "    return dataset\n",
    "\n",
    "ds.ds = resize_images(ds.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "\n",
    "def collate_fn(ex):\n",
    "    dino_images = torch.stack([e[\"dino_image\"] for e in ex])\n",
    "    sam_images = torch.stack([e[\"sam_image\"] for e in ex])\n",
    "    image_ids = [e[\"image_id\"] for e in ex]\n",
    "    pil_images = [e[\"image_pil\"] for e in ex]\n",
    "    return dict(image_ids=image_ids, dino_images=dino_images, sam_images=sam_images, pil_images=pil_images)\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "workers = os.cpu_count()\n",
    "if workers > batch_size:\n",
    "    num_workers = batch_size\n",
    "else:\n",
    "    num_workers = workers\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ds,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "mask_metadata = {}\n",
    "\n",
    "with tqdm(total=len(dataloader)) as pbar:\n",
    "    for batch in dataloader:\n",
    "        image_ids = batch.get(\"image_ids\")\n",
    "        images = batch.get(\"pil_images\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dino_images = batch.get(\"dino_images\").to(device)\n",
    "            sam_images = batch.get(\"sam_images\").to(device)\n",
    "            raw_results = run_grounded_sam_batch(dino_images, sam_images, text_prompt)\n",
    "\n",
    "        for image_id, image, raw_result in zip(image_ids, images, raw_results):\n",
    "            if raw_result.get('masks') is None or ('person' not in raw_result.get(\"phrases\")):\n",
    "                mask_md_row = dict(zip(str(image_id), [None]))\n",
    "\n",
    "            else:\n",
    "\n",
    "                result = SAMResults(image, labels_dict, **raw_result)\n",
    "                mask_md = get_masks_md(result)\n",
    "\n",
    "                mask_md_row = dict(zip(str(image_id), [mask_md]))\n",
    "\n",
    "            mask_metadata.update(mask_md_row)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065d8e92b6c9433aa1497a6ee79a8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5827e61e20174775944bd3252f41f5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Value\n",
    "from huggingface_hub import create_repo\n",
    "updated_ds = ds.ds\n",
    "updated_ds = updated_ds.add_column(\"mask_metadata\", mask_metadata.values())\n",
    "updated_ds = updated_ds.cast_column(\"width\", Value(\"int16\"))\n",
    "updated_ds = updated_ds.cast_column(\"height\", Value(\"int16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11667c52e5984330bf6d9dd480eb3f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_ds = updated_ds.filter(lambda x: x[\"mask_metadata\"] is not None)\n",
    "\n",
    "new_repo_id = \"jordandavis/fashion_people_detections\"\n",
    "create_repo(\n",
    "    repo_id=new_repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    exist_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds.push_to_hub(new_repo_id, commit_message=\"md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groundingdino",
   "language": "python",
   "name": "groundingdino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

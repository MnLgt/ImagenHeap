{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_dataset_v2 import make_yolo_dirs\n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "dataset_dir = Path(\"/Users/jordandavis/GitHub/SEGMENT/datasets/fashion_people_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_dirs = make_yolo_dirs(dataset_dir)\n",
    "yolo_dirs.train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = yolo_dirs.train_img\n",
    "\n",
    "image_files = list(train_img.glob('*.jpg'))\n",
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_dataset_v2 import YoloDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_directory_contents(image_dir: Path, label_dir: Path):\n",
    "    # Create sets of all image and label filenames\n",
    "    image_files = {Path(img.name) for img in image_dir.glob(\"*.jpg\")}\n",
    "    label_files = {Path(img.name) for img in label_dir.glob(\"*.txt\")}\n",
    "\n",
    "    # Convert image filenames to the expected label filenames\n",
    "    expected_label_files = {image.with_suffix(\".txt\") for image in image_files}\n",
    "\n",
    "    # Find mismatches between expected and actual label files\n",
    "    missing_labels = expected_label_files - label_files\n",
    "    extra_labels = label_files - expected_label_files\n",
    "\n",
    "    # Report findings\n",
    "    if not missing_labels and not extra_labels:\n",
    "        logger.info(\n",
    "            f\"All checks passed for {image_dir.name} and {label_dir.name}: Every image has a corresponding label.\"\n",
    "        )\n",
    "    else:\n",
    "        if missing_labels:\n",
    "            logger.info(f\"Missing label files in {label_dir.name}: {missing_labels}\")\n",
    "        if extra_labels:\n",
    "            logger.info(\n",
    "                f\"Extra label files in {label_dir.name} not corresponding to images: {extra_labels}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\n",
    "    \"/Users/jordandavis/GitHub/SEGMENT/datasets/fashion_people_detection/images/val\"\n",
    ")\n",
    "label_dir = Path(\n",
    "    \"/Users/jordandavis/GitHub/SEGMENT/datasets/fashion_people_detection/labels/val\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jordandavis/GitHub/SEGMENT/datasets/fashion_people_detection')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the path of the parent/parent/curdir\n",
    "\n",
    "image_dir.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>level</th>\n",
       "      <th>module</th>\n",
       "      <th>filename</th>\n",
       "      <th>function</th>\n",
       "      <th>line</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 03:53:50 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>main</td>\n",
       "      <td>226</td>\n",
       "      <td>An error occurred in the main function: sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a validation item: format_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-09-26 03:49:02 PM</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>download_dataset_v2</td>\n",
       "      <td>download_dataset_v2.py</td>\n",
       "      <td>process_dataset</td>\n",
       "      <td>177</td>\n",
       "      <td>Error in processing a training item: format_an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_date  level               module  \\\n",
       "0   2024-09-26 03:53:50 PM  ERROR  download_dataset_v2   \n",
       "1   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "2   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "3   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "4   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "5   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "6   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "7   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "8   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "9   2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "10  2024-09-26 03:49:02 PM  ERROR  download_dataset_v2   \n",
       "\n",
       "                  filename         function  line  \\\n",
       "0   download_dataset_v2.py             main   226   \n",
       "1   download_dataset_v2.py  process_dataset   177   \n",
       "2   download_dataset_v2.py  process_dataset   177   \n",
       "3   download_dataset_v2.py  process_dataset   177   \n",
       "4   download_dataset_v2.py  process_dataset   177   \n",
       "5   download_dataset_v2.py  process_dataset   177   \n",
       "6   download_dataset_v2.py  process_dataset   177   \n",
       "7   download_dataset_v2.py  process_dataset   177   \n",
       "8   download_dataset_v2.py  process_dataset   177   \n",
       "9   download_dataset_v2.py  process_dataset   177   \n",
       "10  download_dataset_v2.py  process_dataset   177   \n",
       "\n",
       "                                              message  \n",
       "0   An error occurred in the main function: sequen...  \n",
       "1   Error in processing a validation item: format_...  \n",
       "2   Error in processing a training item: format_an...  \n",
       "3   Error in processing a training item: format_an...  \n",
       "4   Error in processing a training item: format_an...  \n",
       "5   Error in processing a training item: format_an...  \n",
       "6   Error in processing a training item: format_an...  \n",
       "7   Error in processing a training item: format_an...  \n",
       "8   Error in processing a training item: format_an...  \n",
       "9   Error in processing a training item: format_an...  \n",
       "10  Error in processing a training item: format_an...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities.logger_config import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "logger.get_logs('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An error occurred in the main function: sequence item 0: expected str instance, PosixPath found'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.get_logs().loc[0,'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set \n",
    "\n",
    "image_files: Set[Path] = set(image_dir.glob(\"*.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 16:15:51,576 - INFO - All checks passed: Every image in 'val' has a corresponding label in 'val'.\n"
     ]
    }
   ],
   "source": [
    "def check_directory_contents(image_dir: Path, label_dir: Path):\n",
    "    # Create sets of all image and label filenames\n",
    "    image_files: Set[Path] = set(\n",
    "        [file.relative_to(image_dir) for file in image_dir.glob(\"*.jpg\")]\n",
    "    )\n",
    "    label_files: Set[Path] = set(\n",
    "        [file.relative_to(label_dir) for file in label_dir.glob(\"*.txt\")]\n",
    "    )\n",
    "\n",
    "    # Convert image filenames to the expected label filenames\n",
    "    expected_label_files: Set[Path] = {\n",
    "        image.with_suffix(\".txt\") for image in image_files\n",
    "    }\n",
    "\n",
    "    # Find mismatches between expected and actual label files\n",
    "    missing_labels: Set[Path] = expected_label_files - label_files\n",
    "    extra_labels: Set[Path] = label_files - expected_label_files\n",
    "\n",
    "    # Report findings\n",
    "    if not missing_labels and not extra_labels:\n",
    "        logger.info(\n",
    "            f\"All checks passed: Every image in '{image_dir.name}' has a corresponding label in '{label_dir.name}'.\"\n",
    "        )\n",
    "    else:\n",
    "        if missing_labels:\n",
    "            logger.warning(\n",
    "                f\"Missing label files in '{label_dir.name}': {', '.join(str(label) for label in missing_labels)}\"\n",
    "            )\n",
    "        if extra_labels:\n",
    "            logger.warning(\n",
    "                f\"Extra label files in '{label_dir.name}' not corresponding to images: {', '.join(str(label) for label in extra_labels)}\"\n",
    "            )\n",
    "            \n",
    "check_directory_contents(image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groundingdino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

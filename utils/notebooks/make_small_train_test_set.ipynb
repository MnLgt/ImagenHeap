{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil \n",
    "import shutil\n",
    "from yolo_dataset import make_yolo_dirs\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is for making a small train/test set\n",
    "### Rendered somewhat useless by the fact that you can just use the fraction parameter in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_images = 1000\n",
    "num_val_images = int(num_train_images * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dir = \"/home/jordan/SEGMENT/datasets/fashion_people_detection\"\n",
    "fashion_images = os.path.join(fashion_dir, \"images\")\n",
    "fashion_train_images = os.path.join(fashion_images, \"train\")\n",
    "fashion_val_images = os.path.join(fashion_images, \"val\")\n",
    "\n",
    "fashion_labels = os.path.join(fashion_dir, \"labels\")\n",
    "fashion_train_labels = os.path.join(fashion_labels, \"train\")\n",
    "fashion_val_labels = os.path.join(fashion_labels, \"val\")\n",
    "\n",
    "test_dir = \"/home/jordan/SEGMENT/datasets/test\"\n",
    "test_images = os.path.join(test_dir, \"images\")\n",
    "test_train_images = os.path.join(test_images, \"train\")\n",
    "test_val_images = os.path.join(test_images, \"val\")\n",
    "\n",
    "test_labels = os.path.join(test_dir, \"labels\")\n",
    "test_train_labels = os.path.join(test_labels, \"train\")\n",
    "test_val_labels = os.path.join(test_labels, \"val\")\n",
    "\n",
    "# copy five images and their associated labels to the test directory\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "make_yolo_dirs(test_dir)\n",
    "\n",
    "fashion_train_images = [\n",
    "    os.path.join(fashion_train_images, image)\n",
    "    for image in os.listdir(fashion_train_images)\n",
    "]\n",
    "fashion_train_labels = [\n",
    "    os.path.join(fashion_train_labels, label)\n",
    "    for label in os.listdir(fashion_train_labels)\n",
    "]\n",
    "fashion_val_images = [\n",
    "    os.path.join(fashion_val_images, image) for image in os.listdir(fashion_val_images)\n",
    "]\n",
    "fashion_val_labels = [\n",
    "    os.path.join(fashion_val_labels, label) for label in os.listdir(fashion_val_labels)\n",
    "]\n",
    "\n",
    "five_train_images = random.sample(fashion_train_images, num_train_images)\n",
    "\n",
    "five_train_labels = [\n",
    "    image.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "    for image in five_train_images\n",
    "]\n",
    "\n",
    "five_val_images = random.sample(fashion_val_images, num_val_images)\n",
    "\n",
    "five_val_labels = [\n",
    "    image.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "    for image in five_val_images\n",
    "]\n",
    "\n",
    "for image, label in zip(five_train_images, five_train_labels):\n",
    "    shutil.copy(image, test_train_images)\n",
    "    shutil.copy(label, test_train_labels)\n",
    "\n",
    "for image, label in zip(five_val_images, five_val_labels):\n",
    "    shutil.copy(image, test_val_images)\n",
    "    shutil.copy(label, test_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
